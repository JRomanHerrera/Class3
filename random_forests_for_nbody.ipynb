{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación Random Forest para el análisis de simulaciones de N-cuerpos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente cuaderno de trabajo tiene el propósito de ilustrar una aplicación del algoritmo de Random Forest para analizar simulaciones numéricas de formación de estructura en cosmología. La motivación principal de este método (y en general de los trabajos de machine learning sobre simulaciones) es ahorrar el enorme costo computacional de correr y procesar estas simulaciones. Los objetivos específicos de este cuaderno son:\n",
    "\n",
    "- Plantear el problema de formación de halos de materia oscura en términos de un problema de clasificación.\n",
    "- Ejemplificar un flujo de trabajo estándar en problemas de machine learning.\n",
    "- Identificar los hiperparámetros que intervienen en el desarrollo de un modelo de Random Forest y su impacto en el performance del clasificador.\n",
    "- Discutir las principales métricas usadas para evaluar el performance de un clasificador.\n",
    "- Presentar un método de optimización de hiperparámetros.\n",
    "\n",
    "El notebook está preparado para correr con un mínimo de bibliotecas de Python (3+), entre las que se destacan:\n",
    "\n",
    "- Pandas\n",
    "- Seaborn\n",
    "- Scikit-learn\n",
    "\n",
    "A lo largo de este cuaderno se plantean preguntas en <font color='red'> rojo <font color='black'> que tienen como objetivo motivar la discusión sobre los resultados que se obtendrán al correr algunas de las celdas. Siéntanse con la confianza de modificar libremente el código y discutir cualquier duda a:\n",
    "    \n",
    "- Jazhiel Chacón: jazhielchacon@gmail.com\n",
    "- Erick Almaraz : erickalmaraz@gmail.com\n",
    "- Alberto Vázquez: javazquez@icf.unam.mx\n",
    "    \n",
    "    \n",
    "Bienvenidos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:08:52.571231Z",
     "start_time": "2021-06-29T05:08:45.548744Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "sns.set_palette('tab10')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteamiento del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las simulaciones de N-cuerpos sirven de laboratorios numéricos para estudiar el impacto de modelos de materia/energía oscura en los procesos de formación de estructuras cósmicas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"./z49.png\" width=\"320\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">$z=49$</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"./z4.png\" width=\"420\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">$z=4$</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"./z1.png\" width=\"520\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">$z=1$</em>\n",
    "  </p> \n",
    "</td>    \n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"./z0.png\" width=\"620\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">$z=0$</em>\n",
    "  </p> \n",
    "</td>        \n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, <em> correr este tipo de cálculos requiere muchos recursos computacionales </em>. Con los avances en materia de cómputo y métodos de análisis de la información, resulta importante desarrollar aplicaciones que permitan resolver este tipo de limitaciones. \n",
    "\n",
    "En su forma más simple, una simulación de N-cuerpos consta de una colección grande de partículas para las cuales tenemos su posición y velocidad. A continuación, presentamos una muestra de $100,000$ partículas de materia oscura de una simulación que contiene $512^3=134,217,728$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:08:57.739349Z",
     "start_time": "2021-06-29T05:08:57.670322Z"
    }
   },
   "outputs": [],
   "source": [
    "sim49_df = pd.read_pickle('./macss2021_particles_z49.pkl')\n",
    "sim49_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, <em> particle_ID </em> es un identificador que nos ayuda a seguir cada una de ellas a diferentes tiempos. En este caso, los datos de la tabla corresponden al estado cinemático de las partículas en $z=49$, cuando las perturbaciones de la materia seguían siendo relativamente pequeñas. <em> Estas son las condiciones iniciales de la simulación.</em>\n",
    "\n",
    "En los estudios de formación de estructura, una cantidad importante a determinar es la <em> función de masa de halos (HMF)</em>, la cual corresponde a la cantidad de halos por volumen (comóvil) por unidad de masa. Esta cantidad es sensible a la naturaleza de la materia/energía oscura, de modo que su obtención es importante para constreñir la viabilidad de modelos alternativos. Para obtener la HMF es necesario:\n",
    "\n",
    "- Preparar las condiciones iniciales de la simulación\n",
    "- Correr el código de N-cuerpos (<em> esto es lo costoso </em>)\n",
    "- Postprocesar los resultados para encontrar, en este caso, los halos que se forman al final de la simulación (usualmente la época actual)\n",
    "\n",
    "Con el auge de los métodos de inteligencia artificial, podríamos preguntarnos si es posible predecir, aunque sea de manera aproximada, diversos aspectos de una simulación a partir de las condiciones iniciales sin correr el código de N-cuerpos. Si es así, esto podría representar grandes ahorros.\n",
    "\n",
    "\n",
    "<font color='blue'> En este cuaderno seremos un poco más modestos en nuestras pretenciones y nos enfocaremos a predecir si una partícula termina en un halo por encima de cierta masa umbral ($M_{th}$) a partir de la información de las condiciones iniciales. <font color='black'>\n",
    "    \n",
    "Comencemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La simulación que analizaremos corresponde a un modelo $\\Lambda$CDM que corre de $z=49$ a $z=0$. Los parámetros más importantes que necesitamos conocer son:\n",
    "$$N_{part}=512^3,$$ \n",
    "\n",
    "$$L_{box} = 200h^{-1} Mpc,$$ \n",
    "\n",
    "$$h=0.6768.$$ \n",
    "\n",
    "La masa de cada partícula de la simulación es $M_{part}=5.05\\times 10^{9} h^{-1}M_{\\odot}$ y la masa umbral que elegimos es $M_{th}=1.21\\times 10^{12} h^{-1}M_{\\odot}$. Consideraremos el intervalo de masas $M_{low}=100M_{part}$ y $M_{top}=1.5\\times 10^{5}M_{part}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:02.506769Z",
     "start_time": "2021-06-29T05:09:02.501121Z"
    }
   },
   "outputs": [],
   "source": [
    "Mpart = 5.05026e+09        #masa de las partículas (M_\\odot h^{-1}) en la simulaciones\n",
    "Mlow = 100*Mpart           #cota inferior para M \n",
    "Mtop = 150000*Mpart        #cota superior para M\n",
    "\n",
    "#umbral (threshold) de masa para los halos (M_\\odot h^{-1}) para definir las clases IN & OUT\n",
    "Mth = 1.21e+12             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vemos la tabla de arriba, notamos de inmediato que las posiciones y las velocidades son en sí mismas atributos poco informativos. Esto es la norma en cualquier modelo de machile learning. <em> En general, antes de desarrollar un modelo es necesario preprocesar los datos de entrada para construir atributos que puedan ser ingestados en el modelo. Sin eso, los modelos simplemente no funcionan.</em>\n",
    "\n",
    "Para este ejemplo, tomaremos el promedio de la sobredensidad centrada en cada partícula a diferentes escalas $R$:\n",
    "\n",
    "$$\\delta(x;R)=\\int \\delta(x') W_{TH}(x-x';R^3) d^3x',$$\n",
    "\n",
    "donde $W_{TH}$ es una función ventana top-hat con radio característico dado por $R$ y masa de suavizado $M_{s}=\\bar{\\rho}\\frac{4}{3} \\pi R^3$, con $\\bar{\\rho}$ la densidad media de materia. No necesitamos entrar en detalles, solo recordar que  \n",
    "\n",
    "$$M_{s} \\propto R^3,$$ \n",
    "\n",
    "y por lo tanto masas más grandes corresponden a escalas más grandes.</em> Entonces, $\\delta(x;R)$ contiene la información del campo de densidad en la vecindad de cada partícula. De esta manera, buscaremos predecir si una partícula termina en un halo de masa mayor a $M_{th}$ tomando la sobredensidad suavizada en diez escalas entre $M_{low}=100M_{part}$ y $M_{top}=1.5\\times 10^{5}M_{part}$. <font color='red'> ¿Podemos pensar en otros atributos (como por ejemplo, usar la información de la velocidad)? <font color='black'>.\n",
    "    \n",
    "Para encontrar el valor de $\\delta(x;R)$ podemos usar un software como <em> pynbody </em> o <em> pylians </em> (ver referencias). Nosotros aquí presentamos el resultado para las partículas de la tabla de las condiciones iniciales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:06.033863Z",
     "start_time": "2021-06-29T05:09:05.831536Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('./macss2021_dataset.pkl')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, cada partícula está caracterizada por un vector de diez componentes ($dr_i$) y por una etiqueta (label) que indica si:\n",
    "\n",
    "- La partícula cae en un halo de masa mayor a $M_{th}$ en $z=0$: label=1 (IN)\n",
    "\n",
    "- La partícula NO cae en un halo de masa mayor a $M_{th}$ o permanece libre en $z=0$: label=0 (OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de desarrollar un modelo, es importante explorar los datos para ir desarrollando una intuición del problema. Primeramente podemos determinar cuántas partículas tienen label=1 y cuántas tienen label=0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:08.181710Z",
     "start_time": "2021-06-29T05:09:08.128045Z"
    }
   },
   "outputs": [],
   "source": [
    "in_df  = data_df[data_df['label']==1]\n",
    "out_df = data_df[data_df['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:09.483721Z",
     "start_time": "2021-06-29T05:09:09.477979Z"
    }
   },
   "outputs": [],
   "source": [
    "ntotal = len(data_df)\n",
    "nin    = len(in_df)\n",
    "nout   = len(out_df)\n",
    "\n",
    "print('Total de partículas            : ',ntotal)\n",
    "print('Partículas en halo > M_th (IN) : ',nin)\n",
    "print('Partículas en halo < M_th (OUT): ',nout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por la naturaleza aleatoria de $\\delta(x;R)$, podemos obtener el promedio sobre todas las muestras y el máximo valor de esta cantidad para cada una de las escalas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:11.741460Z",
     "start_time": "2021-06-29T05:09:11.473775Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = data_df.loc[:,data_df.columns!='label'].copy()\n",
    "temp_df.describe().loc[['mean','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Qué observamos? ¿tiene esto sentido?. <font color='black'> (<em> Hint: recordemos la relación entre $M_s$ y $R$ y el hecho de que el universo se hace más homogéneo a esclas mayores </em>).\n",
    "    \n",
    "Luego, podemos graficar la distribución de estas cantidades con el propósito de detectar una tendencia en los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:09:24.334286Z",
     "start_time": "2021-06-29T05:09:14.006995Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2,ncols=5,figsize=(20,8))    \n",
    "fig.suptitle('Distribución de la sobredensidad para partículas IN & OUT en diferentes escalas',fontsize=16)\n",
    "\n",
    "dr_cols = data_df.columns[:-1]\n",
    "\n",
    "for idx in range(len(dr_cols)):\n",
    "    temp_col = dr_cols[idx]\n",
    "    \n",
    "    if idx < 5:\n",
    "        sns.distplot(in_df[temp_col],ax=axs[0,idx],kde=True,color='C0',hist=True,label='IN')\n",
    "        sns.distplot(out_df[temp_col],ax=axs[0,idx],kde=True,color='C1',hist=True,label='OUT')\n",
    "        axs[0,idx].axvline(x=0,color='k',linestyle=':')\n",
    "        axs[0,idx].set_xlabel(temp_col,fontsize=15)\n",
    "    else:\n",
    "        sns.distplot(in_df[temp_col],ax=axs[1,idx-5],kde=True,color='C0',hist=True,label='IN')\n",
    "        sns.distplot(out_df[temp_col],ax=axs[1,idx-5],kde=True,color='C1',hist=True,label='OUT')\n",
    "        axs[1,idx-5].axvline(x=0,color='k',linestyle=':')\n",
    "        axs[1,idx-5].set_xlabel(temp_col,fontsize=15)\n",
    "        \n",
    "    if idx == 0:\n",
    "        axs[0,idx].set_ylabel('Densidad de probabilidad',fontsize=15)\n",
    "        axs[0,idx].legend()\n",
    "    if idx == 5: \n",
    "        axs[1,idx-5].set_ylabel('Densidad de probabilidad',fontsize=15)\n",
    "        axs[1,idx-5].legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Qué observamos? ¿tiene esto sentido?. <font color='black'>\n",
    "    \n",
    "Luego, podemos graficar distribuciones conjuntas que nos ayuden a identificar posibles fronteras de separación entre las dos categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:25.528799Z",
     "start_time": "2021-06-29T05:09:24.764401Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data_df,hue=\"label\",corner=True,palette={0:'C1',1:'C0'},plot_kws={'s':7})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Qué observamos? <font color='black'>\n",
    "    \n",
    "Finalmente, vamos a obtener el comportamiento de $\\delta(x;R)$ vs $M_s$ para algunas partículas de ambas categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:36.097690Z",
     "start_time": "2021-06-29T05:10:34.675145Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "fig.suptitle('Sobredensidad suavizada a diferentes escalas',fontsize=15)\n",
    "\n",
    "ax  = plt.subplot(111)\n",
    "\n",
    "logMlow = math.log10(Mlow)\n",
    "logMtop = math.log10(Mtop)\n",
    "logM    = np.linspace(logMlow,logMtop,num=10,endpoint=True) \n",
    "\n",
    "nsamp = 4\n",
    "idx_in  = random.sample(list(in_df.index),nsamp)\n",
    "idx_out = random.sample(list(out_df.index),nsamp)\n",
    "\n",
    "\n",
    "for i in range(nsamp):\n",
    "    if i == 0:\n",
    "        plt.plot(10**logM,in_df.loc[idx_in[i],in_df.columns!='label'],'-',color='C0',linewidth=1.5,label='IN')\n",
    "        plt.plot(10**logM,out_df.loc[idx_out[i],out_df.columns!='label'],'-',color='C1',linewidth=1.5,label='OUT')\n",
    "        plt.legend()\n",
    "    else:\n",
    "        plt.plot(10**logM,in_df.loc[idx_in[i],in_df.columns!='label'],'-',color='C0',linewidth=1.5)\n",
    "        plt.plot(10**logM,out_df.loc[idx_out[i],out_df.columns!='label'],'-',color='C1',linewidth=1.5)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.axvline(x=10**logM[i],color='black',linestyle='dotted',linewidth=0.5)    \n",
    "\n",
    "plt.hlines(0,Mlow,Mtop,colors='black',linestyles='dashed',linewidth=1)\n",
    "\n",
    "plt.xlabel('$M_s (M_\\odot h^{-1})$',fontsize=15)\n",
    "plt.xscale('log')\n",
    "plt.xlim([Mlow,Mtop])\n",
    "plt.ylabel('$\\delta_R$',fontsize=15)\n",
    "minorLocatorY = AutoMinorLocator()\n",
    "ax.yaxis.set_minor_locator(minorLocatorY)\n",
    "plt.tick_params(which='major',length=6)\n",
    "plt.tick_params(which='minor',length=3,color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Qué observamos? <font color='black'>. <em>Aconsejamos correr esto n-veces para ver si detectamos una tendencia. Siéntanse con la confianza de comentar estos resultados al terminar el taller ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción del conjunto de entrenamiento y del conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desarrollar un modelo de machine learning, es necesario hacer una partición en los datos en al menos dos conjuntos:\n",
    "\n",
    "- conjunto de entrenamiento (training): son los datos que se usarán para entrenar el modelo\n",
    "- conjunto de prueba (test): son los datos con los que se evaluará el desempeño del modelo\n",
    "\n",
    "Es importante señalar que los datos del conjunto de prueba no pueden ser utilizados de ninguna manera para entrenar el modelo. En la vida real se usa un tercer conjunto llamado <em> conjunto de validación (validation) </em> con el cual se pueden ajustar los hiperparámetros de un modelo (ver abajo), de modo que el conjunto de prueba se usa sólo para testear el modelo final, sin hacer un ajuste posterior. Aquí solo tomaremos dos conjuntos.\n",
    "\n",
    "Para este ejercicio, tomaremos solo 50000 partículas y reservaremos el 70% para entrenamiento y el 30% para prueba. Notemos que hemos tomado tantas partículas IN como partículas OUT, por lo que las clases están balanceadas. <font color='red'> Siéntanse libres de modificar el tamaño de la muestra (sample_size), la fracción usada para el entrenamiento e incluso hacer dataset con clases desbalanceadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:41.841927Z",
     "start_time": "2021-06-29T05:10:41.839012Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 50000\n",
    "ftrain      = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:43.823852Z",
     "start_time": "2021-06-29T05:10:43.799182Z"
    }
   },
   "outputs": [],
   "source": [
    "#partición del dataset en clases balanceadas\n",
    "\n",
    "assert sample_size//2 <= len(in_df), 'sample_size/2 debe ser <= número total de IN'\n",
    "\n",
    "sample_df = pd.concat([in_df.sample(sample_size//2,random_state=None),\n",
    "                       out_df.sample(sample_size//2,random_state=None)])\n",
    "#para hacer shuffling\n",
    "sample_df = sample_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Cómo haríamos una muestra desbalanceada? <font color='black'>. Hemos visto que $IN/OUT \\approx 0.53$, de modo que una manera de construir un dataset desbalanceado sería simplemente seleccionar N partículas al azar de data_df. <em> Hint: el método 'sample' es de mucha ayuda </em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introducir código aquí\n",
    "#sample_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:44.538636Z",
     "start_time": "2021-06-29T05:10:44.531535Z"
    }
   },
   "outputs": [],
   "source": [
    "arrays = sample_df.to_numpy()\n",
    "X      = arrays[:,0:-1]\n",
    "y      = arrays[:,-1]\n",
    "\n",
    "ntrain   = math.floor(ftrain*len(X))\n",
    "X_train  = X[:ntrain]\n",
    "y_train  = y[:ntrain]\n",
    "\n",
    "X_test   = X[ntrain:]\n",
    "y_test   = y[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del modelo\n",
    "\n",
    "Para implementar una solución de machine learning, podemos desarrollar el código desde cero (aconsejable para modelos sencillos cuando uno está aprendiendo) o bien, usar bibliotecas que ya tienen construidos los modelos y que están optimizadas para correr más eficientemente. Nosotros usaremos la implementación del modelo de Random Forest de la biblioteca <em> scikit-learn </em>, la cual es una biblioteca de amplio uso en materia de machine learning. Otras bibliotecas que pueden ser de interés son <em> PyTorch, TensorFlow & Keras </em>.\n",
    "\n",
    "En scikit-learn, un modelo de Random Forest se configura a través del método <em> RandomForestClassifier </em>. Existen muchas opciones de configuración cuya descripción va más allá del propósito de este cuaderno de trabajo. En nuestro caso las más importantes son:\n",
    "\n",
    "- n_estimators: número de árboles de decisión del modelo\n",
    "- criterion: criterio de partición. Puede ser 'gini' o 'entropy'\n",
    "- max_depth: profundidad máxima de los árboles (None significa que los árboles se extenderán hasta obtener elementos de una misma clase y alcanzar un mínimo en el número de muestras)\n",
    "- max_fratures: número de atributos a considerar para hacer una partición (auto significa sqrt{n_features} = 3 para nuestro problema)\n",
    "- max_samples: número de muestras a tomar de X_train para entrenar un árbol. None significa todas.\n",
    "- bootstrap: Uso de bootstrap para construir las muestras con las que se entrenarán los árboles. Es aconsejable que siempre sea True\n",
    "\n",
    "Otros parámetros de configuración usados para control y debugging son:\n",
    "- n_jobs: número de jobs en paralelo (-1 significa que se usarán todos los procesadores de nuestra máquina)\n",
    "- random_state: Semilla aleatoria. Se puede usar un entero para obtener resultados reproducibles\n",
    "- verbose: bandera para controlar el desplegado de mensajes (0 significa modo silencioso)\n",
    "\n",
    "<font color='red'> Siéntanse con la libertad de modificar estos hiperparámetros a gusto. Más adelante volveremos a esta cuestión. <font color='black'>\n",
    "\n",
    "¿Qué motiva la elección de estos valores? A priori, no hay nada que nos diga que tal o cual valor es más apropiado para hacer que un modelo tenga un mejor desempeño. De hecho, uno de los problemas de desplegar un modelo de machine learning es encontrar la combinación de estos <em> hiperparámetros </em> que optimice el desempeño del modelo. De momento, correremos nuestro modelo con esta configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:10:47.200895Z",
     "start_time": "2021-06-29T05:10:47.197203Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100,\n",
    "                               criterion='entropy',\n",
    "                               max_depth=None,\n",
    "                               max_features='auto',\n",
    "                               max_samples=None,\n",
    "                               bootstrap=True,                               \n",
    "                               n_jobs=None,\n",
    "                               random_state=None,\n",
    "                               verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "Una vez que ya tenemos preparados los datos y configurado nuestro modelo, podemos echar a andar el proceso de entrenamiento. Dependiendo del tipo de modelo, su complejidad y el hardware usado, esto puede tardar en ejecutarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:18.385655Z",
     "start_time": "2021-06-29T05:10:49.448797Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de desempeño\n",
    "\n",
    "Para evaluar el desempeño de nuestro clasificador, podemos definir cantidades que comparen las predicciones con las etiquetas reales de las muestras del conjunto de prueba. Al respecto, recordemos que en las clasificaciones binarias tenemos una clase positiva (en nuestro caso, IN o 1) y una clase negativa (OUT o 0). Al momento de hacer las predicciones del clasificador sobre una muestra, podemos tener los siguientes casos:  \n",
    "\n",
    "- Verdaderos positivos (TP): son las muestras cuya etiqueta real es positiva (IN) y que han sido clasificadas como positivas por el clasificador.\n",
    "- Falsos positivos (FP): son las muestras cuya etiqueta real es negativa (OUT), pero que han sido clasificadas como positivas por el clasificador.\n",
    "- Falsos negativos (FN): son las muestras cuya etiqueta real es positiva (IN), pero que han sido clasificadas como negativas por el clasificador.\n",
    "- Verdaderos negativos (TN): son las muestras cuya etiqueta real es negativa (OUT) y que han sido clasificadas como negativas por el clasificador.\n",
    "\n",
    "Dependiendo del problema, obtener Falsos Positivos podría ser más grave que obtener Falsos Negativos y visceversa, de modo que en ese tipo de situaciones estaríamos mayormente interesados en reducir uno por sobre el otro (por ejemplo, <font color='red'>¿qué efectos tendría una prueba errónea de VIH? <font color='black'>). \n",
    "    \n",
    "A continuación calcularemos las métricas más usadas en este tipo de problemas. Para aterrizar los conceptos, imaginemos que hemos desarrollado un clasificador de imágenes de gatos. En dicho clasificador nuestras muestras se dividen en dos categorías: 'gato' (clase positiva) y 'no-gato' (clase negativa).\n",
    "    \n",
    "    \n",
    "Primero empezamos obteniendo las predicciones del clasificador y las etiquetas reales de las muestras del conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:27.003821Z",
     "start_time": "2021-06-29T05:11:26.565249Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('Predicciones ({})    : {}'.format(len(y_pred),y_pred))\n",
    "print('Etiquetas reales ({}): {}'.format(len(y_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Podemos ver alguna discrepancia en los ejemplos desplegados?, si es así, ¿qué tipo de errores vemos (FP, FN)? \n",
    "    \n",
    "<font color='black'> La siguiente función calcula el número de TP,TN,FP & FN. Los argumentos son las etiquetas reales (y_test) y las predicciones del clasificador (y_pred). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:30.834545Z",
     "start_time": "2021-06-29T05:11:30.819943Z"
    }
   },
   "outputs": [],
   "source": [
    "def performance(y_test,y_pred):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for idx in range(len(y_test)):\n",
    "        if y_test[idx]==y_pred[idx]:\n",
    "            if y_test[idx]==1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "        else:\n",
    "            if y_test[idx]==1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    \n",
    "    return TP, TN, FP, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:32.230460Z",
     "start_time": "2021-06-29T05:11:32.208997Z"
    }
   },
   "outputs": [],
   "source": [
    "TP,TN,FP,FN = performance(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T01:22:31.088782Z",
     "start_time": "2021-06-28T01:22:31.076278Z"
    }
   },
   "source": [
    "#### a) Accuracy\n",
    "\n",
    "La exactitud (accuracy) nos indica la fracción de predicciones acertadas respecto al total:\n",
    "\n",
    "$$accuracy=\\frac{TP+TN}{TP+FP+TN+FN}$$\n",
    "\n",
    "En nuestro ejemplo de los gatos, la exactitud responde a la siguiente pregunta: <em> ¿cuántas de nuestras clasificaciones son correctas? </em>\n",
    "\n",
    "La exactitud es un buen indicador del desempeño de un clasificador, si las muestras están balanceadas, es decir, si la cantidad de muestras con una etiqueta es aproximadamente la misma que la cantidad de muestras con la otra (en nuestro caso, el número de partículas IN tendría que ser similar al número de partículas OUT). En muchas situaciones esta condición no se cumple, por lo que $accuracy \\approx 1$ resulta en un falso optimismo sobre el desempeño del clasificador. <font color='red'>¿Podríamos dar un ejemplo de este caso?, ¿por qué la exactitud no sería una buena métrica? <font color='black'> <em> Hint: consideremos el problema de detección de fraudes en transacciones bancarias. </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:35.344401Z",
     "start_time": "2021-06-29T05:11:34.875266Z"
    }
   },
   "outputs": [],
   "source": [
    "acc_test = model.score(X_test,y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Precision\n",
    "\n",
    "El clasificador va a clasificar cierto número de muestras con la clase positiva (TP, FP). De estas muestras, ¿cuántas son en realidad de la clase positiva? (TP). La precisión o pureza (precision) indica este dato:\n",
    "$$ precision = \\frac{TP}{TP+FP} $$\n",
    "\n",
    "En nuestro ejemplo de los gatos, podemos pensar la precisión en términos de la siguiente pregunta: <em> de todos los objetos clasificados como gatos por nuestro clasificador, ¿cuántos son en realidad gatos? </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:37.683818Z",
     "start_time": "2021-06-29T05:11:37.676582Z"
    }
   },
   "outputs": [],
   "source": [
    "prec_test = float(TP/(TP+FP))\n",
    "prec_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Recall\n",
    "\n",
    "La sensibilidad (recall) es una métrica que mide la capacidad del clasificador de identificar las muestras de la clase positiva:\n",
    "\n",
    "$$ recall = \\frac{TP}{TP+FN} $$\n",
    "\n",
    "En nuestro ejemplo de los gatos, el recall responde a la siguiente pregunta: <em> de todos los gatos en nuestra muestra, ¿cuántos pueden ser identificados por el clasificador? </em>. El recall también es conocido como la True Positive Rate (TPR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:40.987651Z",
     "start_time": "2021-06-29T05:11:40.978619Z"
    }
   },
   "outputs": [],
   "source": [
    "rec_test = float(TP/(TP+FN))\n",
    "rec_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Contamination\n",
    "\n",
    "La contaminación (contamination) mide la cantidad de falsos positivos sobre el total de muestras de la clase negativa:\n",
    "\n",
    "$$ contamination = \\frac{FP}{FP+TN} $$\n",
    "\n",
    "En nuestro ejemplo de los gatos, la contaminación responde a la siguiente pregunta: <em> de todos los objetos que NO son gatos, ¿cuántos de ellos fueron incorrectamente clasificados como gatos? </em>. La contaminación es también conocida como la False Positive Rate (FPR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:42.990882Z",
     "start_time": "2021-06-29T05:11:42.985476Z"
    }
   },
   "outputs": [],
   "source": [
    "cont_test = float(FP/(FP+TN))\n",
    "cont_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Specificity\n",
    "\n",
    "La especificidad (specificity) mide la capacidad del clasificador de identificar las muestras de la clase negativa. En pocas palabras, la especificidad es el recall, pero para la clase negativa:\n",
    "\n",
    "$$ specificity = \\frac{TN}{TN+FP} $$\n",
    "\n",
    "En nuestro ejemplo de los gatos, la especificidad responde a la siguiente pregunta: <em> de todos los no-gatos en nuestra muestra, ¿cuántos de ellos pueden ser identificados por el algoritmo? </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:45.087817Z",
     "start_time": "2021-06-29T05:11:45.080972Z"
    }
   },
   "outputs": [],
   "source": [
    "spec_test = float(TN/(TN+FP))\n",
    "spec_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva ROC y AUC\n",
    "\n",
    "La curva ROC (Receiver Operating Characteristic) y el área debajo de ésta (AUC) es una métrica de mucho uso para medir el desempeño de un clasificador binario. Esta gráfica se construye calculando la TPR y la FPR para diferentes umbrales de discriminación (el umbral de discriminación estándar es 0.5). A manera de referencia, tenemos:\n",
    "\n",
    ".- AUC = 1.0: clasificador perfecto\n",
    "\n",
    ".- AUC = 0.99 - 0.9: muy buen clasificador\n",
    "\n",
    ".- AUC = 0.89 - 0.8: buen clasificador\n",
    "\n",
    ".- AUC = 0.79 - 0.7: clasificador regular \n",
    "\n",
    ".- AUC = 0.69 - 0.6: clasificador malo\n",
    "\n",
    ".- AUC = 0.50: clasificador aleatorio (el modelo no está aprendiendo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:47.396694Z",
     "start_time": "2021-06-29T05:11:46.914228Z"
    }
   },
   "outputs": [],
   "source": [
    "probs_IN = model.predict_proba(X_test)[:,1]\n",
    "#thres[0] se fija arbitrariamente\n",
    "fpr,tpr,thres = roc_curve(y_test,probs_IN)   \n",
    "auc_roc  = roc_auc_score(y_test,probs_IN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Qué valores tiene thres?, ¿qué impacto tiene variar el umbral de discriminación en la TPR (recall) y en la FPR (contaminación)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:49.449408Z",
     "start_time": "2021-06-29T05:11:49.018642Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "fig.suptitle('Curva ROC para el clasificador Random Forest (AUC={:.3f})'.format(auc_roc),fontsize=14)\n",
    "\n",
    "ax  = plt.subplot(111)\n",
    "ax.plot(fpr,tpr,color='C0',linewidth=1.5,linestyle='-',label='Random Forest')\n",
    "ax.plot(fpr,fpr,color='C3',linewidth=1.5,linestyle='--',label='Random Prediction')\n",
    "ax.set_xlabel('False Positive Rate (Contamination)',fontsize=13)\n",
    "ax.set_xlim([-0.01,1])   \n",
    "ax.set_ylabel('True Positive Rate (Recall)',fontsize=13)\n",
    "ax.set_ylim([0,1.05])\n",
    "ax.legend(loc='lower right')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "ax.xaxis.set_minor_locator(minorLocatorX)\n",
    "minorLocatorY = AutoMinorLocator()\n",
    "ax.yaxis.set_minor_locator(minorLocatorY)\n",
    "plt.tick_params(which='major',length=6)\n",
    "plt.tick_params(which='minor',length=3,color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los problemas de clasificación, resulta útil desplegar los resultados de TP, TN, FP & FN en un arreglo que se conoce como <em> matriz de confusión </em>. La matriz de confusión nos ayuda a identificar en dónde el modelo está acertando y en dónde está fallando. Las columnas representan las predicciones y los renglones las etiquetas reales. En scikit-learn, la función <em> confusion_matrix </em> nos ayuda a calcular la matriz de confusión a partir de la información de las etiquetas reales y de las predicciones. La opción <em> normalize </em> despliega los resultados normalizando respecto a las columnas, los renglones, el tamaño de la muestra o sin normalizar (None). <font color='red'> Sería bueno correr la siguiente celda y averiguar el significado de cada una de estas opciones.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:52.563183Z",
     "start_time": "2021-06-29T05:11:52.040339Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_class = model.predict(X_test)\n",
    "confusion_matrix(y_true=y_test,y_pred=pred_class,normalize=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos desplegar estos resultados de una forma visualmente más atractiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:54.919725Z",
     "start_time": "2021-06-29T05:11:54.906178Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_binary_confusion_matrix(model,X_test,y_test,normalize):\n",
    "    '''\n",
    "    Plots the confusion matrix for binary IN/OUT\n",
    "    classification.\n",
    "    \n",
    "    Inputs:\n",
    "        model: a trained model\n",
    "        testX: test set in numpy array format\n",
    "        testy: ground true labels of the objects\n",
    "\n",
    "    Output:\n",
    "        binary_confusion_matrix.pdf: pdf file containing\n",
    "                                     the confusion matrix\n",
    "    '''\n",
    "    \n",
    "    #predicted class (array consisting of 0/1)\n",
    "    #is not the same as predict_proba\n",
    "    pred_class = model.predict(X_test)\n",
    "    \n",
    "    #confusion matrix via sklearn\n",
    "    conf_mat = confusion_matrix(y_true=y_test,y_pred=pred_class,normalize=normalize)\n",
    "    #print(conf_mat)\n",
    "    \n",
    "    classes = ['OUT','IN']\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "    plt.imshow(conf_mat,cmap=plt.cm.Blues,interpolation='nearest',aspect='auto')\n",
    "\n",
    "    #x-axis\n",
    "    tick_marks = np.arange(len(classes))   \n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.xticks(tick_marks,classes,rotation=45)\n",
    "    #y-axis\n",
    "    plt.ylabel('True labels')\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(['OUT','IN']);\n",
    "    plt.ylim([1.5,-0.5])\n",
    "    #to remove the grid in the plot\n",
    "    ax.grid(False)\n",
    "    #loop over data dimensions to create text annotations\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(classes)):\n",
    "            #just to give more visibility to text annotations\n",
    "            if i == j:\n",
    "                color='white'\n",
    "            else:\n",
    "                color='black'            \n",
    "            ax.text(j,i,'{:.3f}'.format(conf_mat[i, j]),ha=\"center\",va=\"center\",color=color)\n",
    "    #export image to file\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('binary_confusion_matrix.pdf')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:11:57.305629Z",
     "start_time": "2021-06-29T05:11:56.572065Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_binary_confusion_matrix(model=model,X_test=X_test,y_test=y_test,normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Cómo se compara la tasa de FP con la de FN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo atractivo de los árboles de decisión es que podemos evaluar el impacto que tienen cada uno de los atributos para hacer una clasificación. Esto nos podría ayudar a identificar aquellos atributos que son más determinantes para nuestro problema. Consideremos, por ejemplo, el peso que tiene un rasgo distintivo como un tatuaje, la forma de los ojos, una cicatriz, la calvicie, etc para identificar a una persona.\n",
    "\n",
    "Algo similar podemos hacer en nuestro problema. El atributo <em> feature_importances_ </em> asigna un score de importancia a cada uno de los atributos $dr_i$ de las muestras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:12:03.617252Z",
     "start_time": "2021-06-29T05:12:03.178272Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model.feature_importances_,index=['dr'+str(i) for i in range(1,11)])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))    \n",
    "fig.suptitle('Features importances para el clasificador Random Forest',fontsize=15)\n",
    "sns.barplot(x=feature_imp.index,y=feature_imp,palette=\"Blues_d\")\n",
    "plt.xlabel('Features',fontsize=15)\n",
    "plt.ylabel('Features Importance Score',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si entrenamos el modelo con los parámetros por default, veremos que la exactitud entre el training y el test set es muy diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:12:10.888827Z",
     "start_time": "2021-06-29T05:12:09.550216Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy en train: {:.3f}'.format(model.score(X_train,y_train)))\n",
    "print('Accuracy en test : {:.3f}'.format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto significa que el modelo aprendió a clasificar muy bien las muestras usadas en el entrenamiento, pero no puede ser usado clasificar con precisión muestras que <em> no ha visto </em> (o sea, el conjunto de prueba). Este problema es conocido como <em> sobreajuste </em> (overfitting) y es con toda seguridad el problema más delicado al momento de desplegar un modelo de machine learning. A final de cuentas, ¿de qué serviría entrenar un modelo si éste no pudiera ser generalizado? \n",
    "\n",
    "Por otro lado, ¿cómo podríamos asegurarnos que hemos elegido los hiperparámetros óptimos para nuestro modelo? \n",
    "\n",
    "¿Cómo podríamos resolver estos dos problemas? A continuación, presentaremos un método muy usado llamado <em> Grid Search </em>, el cual consiste en correr diferentes implementaciones del Random Forest en una cuadrícula (grid) de hiperparámetros. La idea es seleccionar justamente los hiperparámetros que den mejores resultados.\n",
    "\n",
    "Para este problema, nuestra grid consistirá de $3 \\times 3 \\times 3 \\times 3 = 81$ combinaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T05:12:13.591848Z",
     "start_time": "2021-06-29T05:12:13.584839Z"
    }
   },
   "outputs": [],
   "source": [
    "# define models and parameters\n",
    "rf_gs        = RandomForestClassifier()\n",
    "n_estimators = [100,500,1000]\n",
    "max_depth    = [3,8,None]\n",
    "max_features = ['auto',5,None]\n",
    "max_samples  = [0.3,0.6,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para atender el problema de overfitting, podemos hacer una <em> K-Fold Cross-Validation </em>. La idea de esto es que tengamos un modelo optimizado y que a la vez tenga poco sobreajuste.\n",
    "\n",
    "Entonces, de acuerdo a los parámetros que hemos insertado (n_splits=5 & n_repeats=5), correremos un total de 81 modelos $5 \\times 5 = 25$ veces, dando un total de 2025 corridas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T18:00:48.854526Z",
     "start_time": "2021-06-29T18:00:48.791063Z"
    }
   },
   "source": [
    "<font color='red'> <b> Advertencia: dada la cantidad de modelos a evaluar y el total de k-foldings y repeticiones, la siguiente celda se tarda en ejecutar alrededor de 12hr en una máquina de doble núcleo </b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:55:38.250558Z",
     "start_time": "2021-06-29T05:12:15.776714Z"
    }
   },
   "outputs": [],
   "source": [
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            max_features=max_features,\n",
    "            max_samples=max_samples)\n",
    "#cross-validation strategy\n",
    "cv = RepeatedStratifiedKFold(n_splits=5,n_repeats=5,random_state=None)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_gs,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=cv,\n",
    "                           scoring='accuracy',\n",
    "                           error_score=0,\n",
    "                           verbose=4)\n",
    "grid_result = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T17:55:51.205597Z",
     "start_time": "2021-06-29T17:55:51.176881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resultados\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Una vez que hemos encontrado los mejores hiperparámetros, podemos entrenar un modelo con ellos y comparar los resultados respecto a nuestro primer clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T18:00:01.238828Z",
     "start_time": "2021-06-29T17:59:51.191786Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_opt = RandomForestClassifier(n_estimators=#meter_valor,\n",
    "                                criterion='entropy',\n",
    "                                max_depth=#meter_valor,\n",
    "                                max_features=#meter_valor,\n",
    "                                max_samples=#meter_valor,\n",
    "                                bootstrap=True,                               \n",
    "                                n_jobs=None,\n",
    "                                random_state=None,\n",
    "                                verbose=0)\n",
    "\n",
    "rf_opt.fit(X_train,y_train)\n",
    "\n",
    "print('Accuracy en train: {:.3f}'.format(rf_opt.score(X_train,y_train)))\n",
    "print('Accuracy en test : {:.3f}'.format(rf_opt.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> ¿Resolvimos el problema de sobreajuste?, ¿cuál es la exactitud final del modelo optimizado? <font color='black'> Si bien nuestro modelo ya es generalizable, queda pendiente mejorar su desempeño. A este problema se le conoce como <em> bias. </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook hemos visto cómo podemos aplicar un modelo de machine learning para analizar simulaciones cosmológicas. Esperamos que este material haya sido estimulante para explorar esta línea de investigación con mucho potencial. Dejamos este conjunto de referencias e invitamos a mantenernos en contacto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Librerias pygadgetreader & pynbody & pylians para analizar simulaciones de N cuerpos:\n",
    "\n",
    "https://github.com/jveitchmichaelis/pygadgetreader\n",
    "\n",
    "https://pynbody.github.io/pynbody/\n",
    "\n",
    "https://github.com/franciscovillaescusa/Pylians\n",
    "\n",
    "- Random Forest en scikit-learn:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "- Artículos en el que se basó este trabajo:\n",
    "\n",
    "Machine learning cosmological structure formation: https://arxiv.org/abs/1802.04271\n",
    "\n",
    "Classification algorithms applied to structure formation simulations: https://arxiv.org/abs/2106.06587\n",
    "\n",
    "- Compilación de artículos de machine learning aplicados a cosmología:\n",
    "\n",
    "https://github.com/georgestein/ml-in-cosmology"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wfp",
   "language": "python",
   "name": "wfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
